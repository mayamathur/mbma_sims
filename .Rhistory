#
# - The returned Vhat is an estimate of T2 + t2w, *not* T2 itself
# Debugging help:
#
# - The jobs may fail before fitting modAll with no apparent errors if
#   k is too large for rma.mv. In that case, try setting p$k < 500 for modAll
#  and modPub small to prevent those models from being fit.
# for interactive Sherlock:
# path = "/home/groups/manishad/MBMA"
# setwd(path)
# source("doParallel_MBMA.R")
# because Sherlock 2.0 restores previous workspace
rm( list = ls() )
# are we running locally?
run.local = TRUE
# should we set scen params interactively on cluster?
interactive.cluster.run = FALSE
# ~~ Packages -----------------------------------------------
toLoad = c("crayon",
"dplyr",
"foreach",
"doParallel",
"boot",
"metafor",
"robumeta",
"data.table",
"purrr",
"metRology",
"fansi",
"MetaUtility",
"ICC",
"cfdecomp",
"tidyr",
"truncdist",
"tibble",
"tmvtnorm",
"testthat",
"truncreg",
"truncnorm",
"rstan",
"optimx",
"weightr")
if ( run.local == TRUE | interactive.cluster.run == TRUE ) toLoad = c(toLoad, "here")
# SET UP FOR CLUSTER OR LOCAL RUN ------------------------------
# ~~ Cluster Run ----------------------------------------
if (run.local == FALSE) {
# load command line arguments
args = commandArgs(trailingOnly = TRUE)
cat("\n\n args received from sbatch file:", args)
jobname = args[1]
scen = args[2]  # this will be a number
# load packages with informative messages if one can't be installed
# **Common reason to get the "could not library" error: You did ml load R/XXX using an old version
any.failed = FALSE
for (pkg in toLoad) {
cat( paste("\nAbout to try loading package", pkg) )
tryCatch({
# eval below needed because library() will otherwise be confused
# https://www.mitchelloharawild.com/blog/loading-r-packages-in-a-loop/
eval( bquote( library( .(pkg) ) ) )
}, error = function(err) {
cat( paste("\n*** COULD NOT LIBRARYIZE PACKAGE:", pkg) )
any.failed <<- TRUE
})
}
if ( any.failed == TRUE ) stop("Some packages couldn't be installed. See outfile for details of which ones.")
# helper code
path = "/home/groups/manishad/MBMA"
setwd(path)
source("helper_MBMA.R")
# ~~ Cluster Run ----------------------------------------
if ( interactive.cluster.run == FALSE ) {
# get scen parameters (made by genSbatch.R)
setwd(path)
scen.params = read.csv( "scen_params.csv" )
p <<- scen.params[ scen.params$scen == scen, ]
cat("\n\nHEAD OF ENTIRE SCEN.PARAMS:\n")
print(p)
}
# ~~ Interactive Cluster Run ----------------------------------------
# alternatively, generate a simple scen.params in order to run doParallel manually in
# Sherlock as a test
if ( interactive.cluster.run == TRUE ) {
path = "/home/groups/manishad/MBMA"
setwd(path)
source("helper_MBMA.R")
scen.params = tidyr::expand_grid(
# full list (save):
# rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; rtma ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; MBMA-mle-sd ; 2psm-MBMA-dataset ; prereg-naive",
#rep.methods = "naive ; rtma ; 2psm",
rep.methods = "naive ; 2psm ; sapb ; rtma",
# args from sim_meta_2
Nmax = 1,
Mu = c(0.5),
t2a = c(0.2^2),
t2w = c(0.2^2),
m = 50,
hack = c("affirm2"),
rho = c(0),
k.pub.nonaffirm = c(15),
prob.hacked = c(0),
eta = 5,
true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)"),
muB = log(2),
sig2B = 0.5,
prob.conf = 0.5,
# Stan control args
stan.maxtreedepth = 20,
stan.adapt_delta = 0.80,
get.CIs = TRUE,
run.optimx = FALSE )
scen.params$scen = 1:nrow(scen.params)
scen = 1
}  # end "if ( interactive.cluster.run == TRUE )"
# locally, with total k = 100, Nmax = 10, and sim.reps = 250, took 93 min total
# for that I did sim.reps = 100 per doParallel
# simulation reps to run within this job
# **this need to match n.reps.in.doParallel in the genSbatch script
if ( interactive.cluster.run == FALSE ) sim.reps = 200
if ( interactive.cluster.run == TRUE ) sim.reps = 1
# set the number of cores
registerDoParallel(cores=16)
}
# FOR LOCAL USE  ------------------------------
if ( run.local == TRUE ) {
#rm(list=ls())
lapply( toLoad,
require,
character.only = TRUE)
# helper fns
code.dir = here()
setwd(code.dir)
source("helper_MBMA.R")
# ~~ Set Local Sim Params -----------------------------
scen.params = tidyr::expand_grid(
# full list (save):
# rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; rtma ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; MBMA-mle-sd ; 2psm-MBMA-dataset ; prereg-naive",
#rep.methods = "naive ; rtma ; 2psm",
rep.methods = "naive ; sapb ; 2psm",
# args from sim_meta_2
Nmax = 1,
Mu = c(0.5),
t2a = c(0.2^2),
t2w = c(0.2^2),
m = 50,
hack = c("affirm2"),
rho = c(0),
k.pub.nonaffirm = c(15),
prob.hacked = c(0),
eta = 5,
true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)"),
muB = log(2),
sig2B = 0.5,
prob.conf = 0,
# Stan control args
stan.maxtreedepth = 20,
stan.adapt_delta = 0.80,
get.CIs = TRUE,
run.optimx = FALSE )
scen.params$scen = 1:nrow(scen.params)
sim.reps = 1  # reps to run in this iterate
# set the number of local cores
registerDoParallel(cores=8)
scen = 1
# data.frame(scen.params %>% filter(scen.name == scen))
# just to avoid errors in doParallel script below
jobname = "job_1"
i = 1
}
# only print info for first sim rep for visual clarity
if ( i == 1 ) cat("\n\n~~~~~~~~~~~~~~~~ BEGIN SIM REP", i, "~~~~~~~~~~~~~~~~")
# results for just this simulation rep
if ( exists("rep.res") ) suppressWarnings( rm(rep.res) )
# extract simulation params for this scenario (row)
# exclude the column with the scenario name itself (col)
cat("\n\n scen variable:\n")
print(scen)
cat("\n\n scen.params again:\n")
print(scen.params)
p = scen.params[ scen.params$scen == scen, names(scen.params) != "scen"]
# calculate TOTAL heterogeneity
p$V = p$t2a + p$t2w
p$S = sqrt(p$V)
if ( i == 1 ) cat("\n\nDIM AND HEAD OF P (SINGLE ROW OF SCEN.PARAMS):\n")
if ( i == 1 ) print(dim(p)); print(p); print(p$Mu)
# parse methods string
all.methods = unlist( strsplit( x = p$rep.methods,
split = " ; " ) )
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
names(d)
# ~~ Set Local Sim Params -----------------------------
scen.params = tidyr::expand_grid(
# full list (save):
# rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; rtma ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; MBMA-mle-sd ; 2psm-MBMA-dataset ; prereg-naive",
#rep.methods = "naive ; rtma ; 2psm",
rep.methods = "naive ; sapb ; 2psm",
# args from sim_meta_2
Nmax = 1,
Mu = c(0.5),
t2a = c(0.2^2),
t2w = c(0.2^2),
m = 50,
hack = c("affirm2"),
rho = c(0),
k.pub.nonaffirm = c(200), # TEMP: HUGE
prob.hacked = c(0),
eta = 5,
true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)"),
muB = log(2),
sig2B = 0.5,
prob.conf = 0.5,
# Stan control args
stan.maxtreedepth = 20,
stan.adapt_delta = 0.80,
get.CIs = TRUE,
run.optimx = FALSE )
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
d %>%
filter(Di == 1 & Di.across == 1) %>%
group_by(Ci, affirm) %>%
summarise(n(),
mean(Bi),
mean(mui),
mean(yi))
# only print info for first sim rep for visual clarity
if ( i == 1 ) cat("\n\n~~~~~~~~~~~~~~~~ BEGIN SIM REP", i, "~~~~~~~~~~~~~~~~")
# results for just this simulation rep
if ( exists("rep.res") ) suppressWarnings( rm(rep.res) )
# extract simulation params for this scenario (row)
# exclude the column with the scenario name itself (col)
cat("\n\n scen variable:\n")
print(scen)
cat("\n\n scen.params again:\n")
print(scen.params)
p = scen.params[ scen.params$scen == scen, names(scen.params) != "scen"]
# calculate TOTAL heterogeneity
p$V = p$t2a + p$t2w
p$S = sqrt(p$V)
if ( i == 1 ) cat("\n\nDIM AND HEAD OF P (SINGLE ROW OF SCEN.PARAMS):\n")
if ( i == 1 ) print(dim(p)); print(p); print(p$Mu)
# parse methods string
all.methods = unlist( strsplit( x = p$rep.methods,
split = " ; " ) )
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
d %>%
filter(Di == 1 & Di.across == 1) %>%
group_by(Ci, affirm) %>%
summarise(n(),
mean(Bi),
mean(mui),
mean(yi))
p$prob.conf
# ~~ Set Local Sim Params -----------------------------
scen.params = tidyr::expand_grid(
# full list (save):
# rep.methods = "naive ; gold-std ; pcurve ; maon ; 2psm ; rtma ; jeffreys-sd ; jeffreys-var ; mle-sd ; mle-var ; MBMA-mle-sd ; 2psm-MBMA-dataset ; prereg-naive",
#rep.methods = "naive ; rtma ; 2psm",
rep.methods = "naive ; sapb ; 2psm",
# args from sim_meta_2
Nmax = 1,
Mu = c(0.5),
t2a = c(0.2^2),
t2w = c(0.2^2),
m = 50,
hack = c("affirm2"),
rho = c(0),
k.pub.nonaffirm = c(200), # TEMP: HUGE
prob.hacked = c(0),
eta = 5,
true.sei.expr = c("0.02 + rexp(n = 1, rate = 3)"),
muB = log(2),
sig2B = 0.5,
prob.conf = 0.5,
# Stan control args
stan.maxtreedepth = 20,
stan.adapt_delta = 0.80,
get.CIs = TRUE,
run.optimx = FALSE )
scen.params$scen = 1:nrow(scen.params)
sim.reps = 1  # reps to run in this iterate
# set the number of local cores
registerDoParallel(cores=8)
scen = 1
# data.frame(scen.params %>% filter(scen.name == scen))
# just to avoid errors in doParallel script below
jobname = "job_1"
i = 1
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
names(d)
d %>%
filter(Di == 1 & Di.across == 1) %>%
group_by(Ci, affirm) %>%
summarise(n(),
mean(Bi),
mean(mui),
mean(yi))
p$prob.conf
print(scen.params)
scen.params$prob.conf
scen
scen.params$scen
p = scen.params[ scen.params$scen == scen, names(scen.params) != "scen"]
# calculate TOTAL heterogeneity
p$V = p$t2a + p$t2w
p$S = sqrt(p$V)
if ( i == 1 ) cat("\n\nDIM AND HEAD OF P (SINGLE ROW OF SCEN.PARAMS):\n")
if ( i == 1 ) print(dim(p)); print(p); print(p$Mu)
# parse methods string
all.methods = unlist( strsplit( x = p$rep.methods,
split = " ; " ) )
p$prob.conf
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
# ~ Simulate Dataset ------------------------------
# includes unpublished studies
d = sim_meta_2( Nmax = p$Nmax,
Mu = p$Mu,
t2a = p$t2a,
m = p$m,
t2w = p$t2w,
true.sei.expr = p$true.sei.expr,
hack = p$hack,
rho = p$rho,
eta = p$eta,
muB = p$muB,
sig2B = p$sig2B,
prob.conf = p$prob.conf,
k.pub.nonaffirm = p$k.pub.nonaffirm,
prob.hacked = p$prob.hacked,
return.only.published = FALSE)
d %>%
filter(Di == 1 & Di.across == 1) %>%
group_by(Ci, affirm) %>%
summarise(n(),
mean(Bi),
mean(mui),
mean(yi))
table(d$Di)
table(d$Di.across)
mean( d$Bi[ d$Ci == 1 & Di == 1] )
mean( d$Bi[ d$Ci == 1 & d$Di == 1] )
mean(dp$Bi[ dp$Ci == 1])
d$Zi = d$yi / sqrt(d$vi)
# ~ ******* MBMA: Pre-Adjust Estimates, Crit Values, Variances ------------------------------
d$yi.adj = d$yi - d$Ci * p$muB
d$vi.adj = d$vi + d$Ci * p$sig2B
d$tcrit.adj = d$tcrit
d$tcrit.adj[ d$Ci == 1 ] = ( d$tcrit[ d$Ci == 1 ] * sqrt(d$vi[ d$Ci == 1 ]) - p$muB ) / sqrt(d$vi.adj[ d$Ci == 1 ])
# d %>% group_by(Ci) %>%
#   summarise( mean(yi),
#              mean(yi.adj),
#              mean(vi.adj),
#              mean(tcrit),
#              mean(tcrit.adj))
expect_equal( d$affirm,
d$yi > d$tcrit * sqrt(d$vi) )
# confirm that adjusted affirmative threshold is equivalent to the old one
expect_equal( d$affirm,
d$yi.adj > d$tcrit.adj * sqrt(d$vi.adj) )
# ~ Dataset Subsets for Various Methods ------------------------------
# dataset of only favored AND published results
dp = d %>% filter(Di == 1 & Di.across == 1)
# keep first draws only
d.first = d[ !duplicated(d$study), ]
# published nonaffirmatives only
dpn = dp[ dp$affirm == FALSE, ]
# published affirmatives only
dpa = dp[ dp$affirm == TRUE, ]
# this is like analyzing only preregistered studies
dp.unhacked = dp %>% filter(hack == "no")
if ( i == 1 ) cat("\n\nHEAD OF DP:\n")
if ( i == 1 ) print(head(dp))
# ~ Start Values ------------------------------
# initialize rep.res st run_method_safe and other standalone estimation fns
#  will correctly recognize it as having 0 rows
rep.res = data.frame()
Mhat.start = p$Mu
Shat.start = p$S
# in case we're not doing rtma or it fails
Mhat.MaxLP = NA
Shat.MaxLP = NA
Mhat.MAP = NA
Shat.MAP = NA
mean( d$Bi[ d$Ci == 1 & d$Di == 1] )
mean( dp$Bi[ dp$Ci == 1 & dp$Di == 1] )
# P(A^*_i = 1 | C^*_i = 1) from P(A^*_i = 1 | C^*_i = 1, D^*_i = 1)
pa = mean( dp$affirm[ dp$Ci == 1 ] )
pa
# P(A^*_i = 1 | C^*_i = 1) from P(A^*_i = 1 | C^*_i = 1, D^*_i = 1)
pa.obs = mean( dp$affirm[ dp$Ci == 1 ] )
pna.obs = 1 - pa.obs
denom = pa.obs + p$eta * pna.obs
denom
EB.a.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 1] )
EB.na.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 0] )
EB.a.obs
EB.na.obs
(1/denom) * ( pna.obs*p$eta*EB.na.obs + pa.obs*EB.a.obs )
& d$Di == 1
# underlying one
mean( d$Bi[ d$Ci == 1 & d$Di == 1] )
# uncorrected one (just for comparison)
mean( dp$Bi[ dp$Ci == 1 ] )
# also should be close to...
p$muB * p$prob.conf
# also should be close to...
p$muB
mean( dp$affirm[ dp$Ci == 1 ] )
P.affirm.pub = mean( dp$affirm[ dp$Ci == 1 ] )
# and P(A^*_i = 0 | C^*_i = 1):
P.nonaffirm.pub = 1 - pa.obs
# mean
EB.affirm.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 1] )
EB.nonaffirm.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 0] )
denom = P.affirm.pub + p$eta * P.nonaffirm.pub
P.affirm.pub = mean( dp$affirm[ dp$Ci == 1 ] )
# and P(A^*_i = 0 | C^*_i = 1):
P.nonaffirm.pub = 1 - pa.obs
# mean
EB.affirm.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 1] )
EB.nonaffirm.obs = mean( dp$Bi[ dp$Ci == 1 & dp$affirm == 0] )
denom = P.affirm.pub + p$eta * P.nonaffirm.pub
# called "gamma" on iPad
# a sample estimate of muB
MhatB = (1/denom) * ( P.nonaffirm.pub * p$eta * EB.nonaffirm.obs +
P.affirm.pub * EB.affirm.obs )
MhatB
# uncorrected one (just for comparison)
# will be way too high
mean( dp$Bi[ dp$Ci == 1 ] )
mean( d$Bi[ d$Ci == 1 & d$Di == 1] )
# also should be close to...
p$muB
