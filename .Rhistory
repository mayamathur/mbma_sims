AbsBiasMax = max(MhatAbsBias),
RMSEMin = min(MhatAbsBias),
RMSEMd = median(MhatAbsBias),
RMSEMax = max(MhatAbsBias),
#*express coverage as percent
CoverMin = 100*min(MhatCover),
CoverMd = 100*median(MhatCover),
WidthMd = median(MhatWidth),
WidthMin = min(MhatWidth),
WidthMax = max(MhatWidth),
MhatEstFail = median(MhatEstFail) )
t
string = paste( i, "~", paste(param.vars.manip, collapse = "+"), sep="" )
( string = paste( i, "~", paste(param.vars.manip, collapse = "+"), sep="" ) )
method = "mbma-MhatB"
.method = "mbma-MhatB"
( string = paste( outcome, "~", paste(param.vars.manip, collapse = "+"), sep="" ) )
mod = lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) )
outcome = "MhatBias"
.method = "mbma-MhatB"
( string = paste( outcome, "~", paste(param.vars.manip, collapse = "+"), sep="" ) )
mod = lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) )
mod
library(broom)
broom(mod)
( string = paste( "(MhatBias < 0) ~", paste(param.vars.manip, collapse = "+"), sep="" ) )
mod = lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) )
tidy(mod)
.method = "2psm"
( string = paste( "(MhatBias < 0) ~", paste(param.vars.manip, collapse = "+"), sep="" ) )
mod = lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) )
library(broom)
tidy(mod)
# scens with SAS.type=carter
make_both_winner_tables(.agg = agg %>% filter(SAS.type == "carter") )
.method = "mbma-MhatB"
( string = paste( "(MhatBias < 0) ~", paste(param.vars.manip, collapse = "+"), sep="" ) )
tidy( lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) ) )
.method = "2psm"
tidy( lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) ) )
# scenarios where our method IS correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 0) )
table(agg$true.sei.expr)
# larger within-study SEs
make_both_winner_tables(.agg = agg %>% filter("0.02 + rexp(n = 1, rate = 1)") )
# larger within-study SEs
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr =="0.02 + rexp(n = 1, rate = 1)") )
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr == "0.02 + rexp(n = 1, rate = 3)") )
table(agg$muB)
# small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
make_both_winner_tables(.agg = agg %>% filter(muB > 0.1) )
# small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# all scenarios
# here, reason SM-step appears unbiased is that it's positively biased under evil.selection=0
#   but negatively biased under evil.selection=1
make_both_winner_tables(.agg = agg)
# small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr == "0.02 + rexp(n = 1, rate = 1)") )
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr == "0.02 + rexp(n = 1, rate = 3)") )
# skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
# For Reviewer 3's questions
# larger within-study SEs
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr == "0.02 + rexp(n = 1, rate = 1)") )
# small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
update_result_csv( name = "n scens large SEs",
value = nuni(agg$scen.name[ agg$true.sei.expr == "0.02 + rexp(n = 1, rate = 1)"]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens small muB",
value = nuni(agg$scen.name[ agg$muB == 0.1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# 3: scenarios where our method is NOT correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 1) )
# 2: scenarios where our method IS correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 0) )
# 3: scenarios where our method is NOT correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 1) )
update_result_csv( name = "prop scens evilselect1",
value = mean(agg$scen.name[ agg$evil.selection == 1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "prop scens evilselect1",
value = round( 100*mean(agg$evil.selection == 1) ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
800/864
819/864
(819+25)/864
(831+25)/864
rm(list=ls())
# data-wrangling packages
library(here)
library(plotly)  # must be BEFORE dplyr or else plotly::select will take over
library(dplyr)
library(tibble)
library(ggplot2)
library(data.table)
library(tidyverse)
library(fastDummies)
library(xlsx)
library(tableone)
# meta-analysis packages
library(metafor)
library(robumeta)
# other
library(xtable)
library(testthat)
library(Deriv)
library(mosaic)
library(hpa)
library(pracma)
library(truncnorm)
library(tmvtnorm)
library(RColorBrewer)
library(sjmisc)
library(broom)
# prevent masking
select = dplyr::select
# ~~ User-specified global vars -------------------------
# no sci notation
options(scipen=999)
# control which results should be redone and/or overwritten
# e.g., sim_plot_multiple_outcomes
#@ not all fns respect this setting
overwrite.res = TRUE
# ~~ Set directories -------------------------
code.dir = here()
data.dir = str_replace( string = here(),
pattern = "Code",
replacement = "Results/2023-04-09 full sims for manuscript (RSM_1)" )
# temp while sims are ongoing
results.dir = data.dir
# results.dir = str_replace( string = here(),
#                            pattern = "Code",
#                            replacement = "Results/*2022-7-23 More scens for manuscript; add mbma-MhatB-true-t2" )
overleaf.dir.figs = "/Users/mmathur/Dropbox/Apps/Overleaf/Multiple-bias meta-analysis Overleaf (MBMA)/figures/sims"
# for stats_for_paper.csv
# same dir as for applied examples so that they'll write to single file
overleaf.dir.nums = "/Users/mmathur/Dropbox/Apps/Overleaf/Multiple-bias meta-analysis Overleaf (MBMA)/R_objects"
setwd(code.dir)
source("helper_MBMA.R")
source("analyze_sims_helper_MBMA.R")
setwd(data.dir)
aggo = fread("agg.csv")
# check when the dataset was last modified to make sure we're working with correct version
file.info( paste(data.dir, "agg.csv", sep="/") )$mtime
nrow(aggo)  # will exceed number of scens because of multiple methods
expect_equal( 12980, nuni(aggo$scen.name) )
# proportion done
nuni(aggo$scen.name) / 12980
# prettify variable names
agg = wrangle_agg_local(aggo)
# initialize global variables that describe estimate and outcome names, etc.
# this must be after calling wrangle_agg_local
init_var_names()
#@temp
table(agg$method)
agg = agg %>% filter(!(method %in% c("mbma-MhatB-gamma", "maon-adj-MhatB")))
# make new var
agg$MhatEstConverge = 1 - agg$MhatEstFail
# for analyzing sims as they run:
# which key scen params have run so far?
CreateCatTable(vars = param.vars.manip,  # param.vars.manip is from init_var_names
data = agg)
# ONE-OFF STATS FOR PAPER  -------------------------
# scenario counts
update_result_csv( name = "n scens",
value = nuni(agg$scen.name),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens evilselect0",
value = nuni(agg$scen.name[ agg$evil.selection == 0]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens evilselect1",
value = nuni(agg$scen.name[ agg$evil.selection == 1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "prop scens evilselect1",
value = round( 100*mean(agg$evil.selection == 1) ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens smallk",
value = nuni(agg$scen.name[ agg$k.pub.nonaffirm == 5]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens skewed",
value = nuni(agg$scen.name[ agg$true.dist == "expo"]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens large SEs",
value = nuni(agg$scen.name[ agg$true.sei.expr == "0.02 + rexp(n = 1, rate = 1)"]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens small muB",
value = nuni(agg$scen.name[ agg$muB == 0.1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# convergence
update_result_csv( name = "beta-sm convergence",
value = round( 100*median(agg$MhatEstConverge[agg$method == "beta-sm"]), 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# sample sizes
update_result_csv( name = paste( "sancheck.dp.k", c("Q1", "median", "Q3") ),
value = round( summary(agg$sancheck.dp.k)[2:4], 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = paste( "sancheck.dp.k.affirm", c("Q1", "median", "Q3") ),
value = round( summary(agg$sancheck.dp.k.affirm)[2:4], 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# 1: all scenarios
make_both_winner_tables(.agg = agg)
.method = "mbma-MhatB"
( string = paste( "(MhatBias < 0) ~", paste(param.vars.manip, collapse = "+"), sep="" ) )
tidy( lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) ) )
.method = "2psm"
tidy( lm( eval(parse(text=string)),
data = agg %>% filter(method == .method) ) )
# 1: all scenarios
make_both_winner_tables(.agg = agg)
# 2: scenarios where our method IS correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 0) )
# 3: scenarios where our method is NOT correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 1) )
n
# 4: small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# 5: small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
# 6: skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
sum(agg$doParallel.seconds)
sum(agg$doParallel.seconds, ra.rm=TRUE)
agg$doParallelSeconds
sum(agg$doParallelSeconds)/(60*60*12)
sum(agg$doParallelSeconds, na.rm=TRUE)/(60*60*12)
sim(agg)
dim(agg)
4*60
(4*12490)/12
(4*864)/12
(4*864)/24
(5*864)/24
rm(list=ls())
# data-wrangling packages
library(here)
library(plotly)  # must be BEFORE dplyr or else plotly::select will take over
library(dplyr)
library(tibble)
library(ggplot2)
library(data.table)
library(tidyverse)
library(fastDummies)
library(xlsx)
library(tableone)
# meta-analysis packages
library(metafor)
library(robumeta)
# other
library(xtable)
library(testthat)
library(Deriv)
library(mosaic)
library(hpa)
library(pracma)
library(truncnorm)
library(tmvtnorm)
library(RColorBrewer)
library(sjmisc)
library(broom)
# prevent masking
select = dplyr::select
# ~~ User-specified global vars -------------------------
# no sci notation
options(scipen=999)
# control which results should be redone and/or overwritten
# e.g., sim_plot_multiple_outcomes
#@ not all fns respect this setting
overwrite.res = TRUE
# ~~ Set directories -------------------------
code.dir = here()
data.dir = str_replace( string = here(),
pattern = "Code",
replacement = "Results/2023-04-09 full sims for manuscript (RSM_1)" )
# temp while sims are ongoing
results.dir = data.dir
# results.dir = str_replace( string = here(),
#                            pattern = "Code",
#                            replacement = "Results/*2022-7-23 More scens for manuscript; add mbma-MhatB-true-t2" )
overleaf.dir.figs = "/Users/mmathur/Dropbox/Apps/Overleaf/Multiple-bias meta-analysis Overleaf (MBMA)/figures/sims"
# for stats_for_paper.csv
# same dir as for applied examples so that they'll write to single file
overleaf.dir.nums = "/Users/mmathur/Dropbox/Apps/Overleaf/Multiple-bias meta-analysis Overleaf (MBMA)/R_objects"
setwd(code.dir)
source("helper_MBMA.R")
source("analyze_sims_helper_MBMA.R")
# ~~ Get agg data -------------------------
setwd(data.dir)
aggo = fread("agg.csv")
# check when the dataset was last modified to make sure we're working with correct version
file.info( paste(data.dir, "agg.csv", sep="/") )$mtime
nrow(aggo)  # will exceed number of scens because of multiple methods
expect_equal( 12980, nuni(aggo$scen.name) )
# proportion done
nuni(aggo$scen.name) / 12980
# prettify variable names
agg = wrangle_agg_local(aggo)
# initialize global variables that describe estimate and outcome names, etc.
# this must be after calling wrangle_agg_local
init_var_names()
# remove experimental methods
table(agg$method)
agg = agg %>% filter(!(method %in% c("mbma-MhatB-gamma", "maon-adj-MhatB")))
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# prettify variable names
agg = wrangle_agg_local(aggo)
head(agg$MhatEstConverge)
init_var_names()
# remove experimental methods
table(agg$method)
agg = agg %>% filter(!(method %in% c("mbma-MhatB-gamma", "maon-adj-MhatB")))
# for analyzing sims as they run:
# which key scen params have run so far?
CreateCatTable(vars = param.vars.manip,  # param.vars.manip is from init_var_names
data = agg)
#@later: what's up with the scens that have SAS.type or hack empty?
temp = agg %>% filter(true.dist == "")
dim(temp)
View(temp)
agg = agg %>% filter( !is.na(scen.name) )
agg %>% filter(true.dist == "")
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# prettify variable names
agg = wrangle_agg_local(aggo)
# initialize global variables that describe estimate and outcome names, etc.
# this must be after calling wrangle_agg_local
init_var_names()
# remove experimental methods
table(agg$method)
agg = agg %>% filter(!(method %in% c("mbma-MhatB-gamma", "maon-adj-MhatB")))
# for analyzing sims as they run:
# which key scen params have run so far?
CreateCatTable(vars = param.vars.manip,  # param.vars.manip is from init_var_names
data = agg)
# scenario counts
update_result_csv( name = "n scens",
value = nuni(agg$scen.name),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens evilselect0",
value = nuni(agg$scen.name[ agg$evil.selection == 0]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens evilselect1",
value = nuni(agg$scen.name[ agg$evil.selection == 1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "prop scens evilselect1",
value = round( 100*mean(agg$evil.selection == 1) ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens smallk",
value = nuni(agg$scen.name[ agg$k.pub.nonaffirm == 5]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens skewed",
value = nuni(agg$scen.name[ agg$true.dist == "expo"]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens large SEs",
value = nuni(agg$scen.name[ agg$true.sei.expr == "0.02 + rexp(n = 1, rate = 1)"]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = "n scens small muB",
value = nuni(agg$scen.name[ agg$muB == 0.1]),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# convergence
update_result_csv( name = "beta-sm convergence",
value = round( 100*median(agg$MhatEstConverge[agg$method == "beta-sm"]), 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# sample sizes
update_result_csv( name = paste( "sancheck.dp.k", c("Q1", "median", "Q3") ),
value = round( summary(agg$sancheck.dp.k)[2:4], 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
update_result_csv( name = paste( "sancheck.dp.k.affirm", c("Q1", "median", "Q3") ),
value = round( summary(agg$sancheck.dp.k.affirm)[2:4], 0 ),
.results.dir = results.dir,
.overleaf.dir = overleaf.dir.nums )
# 1: all scenarios
make_both_winner_tables(.agg = agg)
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# 1: all scenarios
make_both_winner_tables(.agg = agg)
# 2: scenarios where our method IS correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 0) )
# 3: scenarios where our method is NOT correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 1) )
# 4: small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# 5: small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5), display="dataframe")
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# 4: small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# 1: all scenarios
make_both_winner_tables(.agg = agg)
# 5: small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# 5: small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
# 6: skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
# display: "xtable" or "dataframe"
make_winner_table = function( .agg,
.yNames = c("MhatBias", "MhatAbsBias", "MhatRMSE", "MhatCover", "MhatWidth", "MhatEstConverge"),
summarise.fun.name,
display = "dataframe"){
for ( .yName in .yNames ){
newCol = make_winner_table_col(.agg = .agg,
yName = .yName,
summarise.fun.name = summarise.fun.name )
if ( .yName == .yNames[1] ) t.all = newCol else t.all = suppressMessages( bind_cols(t.all, newCol) )
}
cat( paste("\n\n**** WINNER TABLE", summarise.fun.name) )
cat( paste("\n\n     Number of scens:", nuni(.agg$scen.name),
"; proportion of all scens: ",
round( nuni(.agg$scen.name) / nuni(agg$scen.name), 3 ) ) )
cat("\n\n")
if (display == "xtable") {
print( xtable( data.frame(t.all) ), include.rownames = FALSE )
}
if (display == "dataframe") {
print( data.frame(t.all) )
}
#return(t.all)
}
source("~/Dropbox/Personal computer/Independent studies/2020/Multiple-bias meta-analysis (MBMA)/Linked to OSF (MBMA)/Simulation study/Code/analyze_sims_helper_MBMA.R")
# 6: skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
# 6: skewed effects
make_both_winner_tables(.agg = agg %>% filter(true.dist=="expo") )
# For Reviewer 3's questions
# 7: larger within-study SEs
make_both_winner_tables(.agg = agg %>% filter(true.sei.expr == "0.02 + rexp(n = 1, rate = 1)") )
# 1: all scenarios
make_both_winner_tables(.agg = agg)
# 2: scenarios where our method IS correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 0) )
# 3: scenarios where our method is NOT correctly spec
make_both_winner_tables(.agg = agg %>% filter(evil.selection == 1) )
# 4: small k.pub.nonaffirm
make_both_winner_tables(.agg = agg %>% filter(k.pub.nonaffirm == 5) )
# 5: small mean bias
make_both_winner_tables(.agg = agg %>% filter(muB == 0.1) )
1 - .9^30
1-.9
1-.94^30
1-.95^2
1-.95
1-.95^20
1-.94^30
40-17
1-.94^20
n = 50000
A = rbinom(n = n,
size = 1,
prob = 0.3)
epsY = rbinom(n = n,
size = 1,
prob = 0.4)
Y = epsY
Y1 = Y
epsR = epsY
R1 = pmax(1, epsR)  # all 1
R0 = pmax(0, epsR)
R = A*R1 + (1-A)*R0
# counterfactual
mean(Y1[R==1])
# factual
mean(Y[A==1 & R==1])
mean(Y)
70_50+5+20
70+50+5+20
63750*1.4
85000*.6
3750*1.33
63750*1.33
63750*.33
library(metafor)
?selmodel
